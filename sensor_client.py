#!/usr/bin/env python3
"""
Remote Sensor Client
Lightweight network monitor for distributed deployment (e.g., Nano Pi)

Captures and analyzes traffic locally, then batches alerts to central SOC server.
"""

import os
import sys
import time
import logging
import socket
import psutil
import requests
import argparse
import signal
from datetime import datetime
from collections import deque
from pathlib import Path

# Add current dir to path
sys.path.insert(0, str(Path(__file__).parent))

from config_loader import load_config
from detector import ThreatDetector
from threat_feeds import ThreatFeedManager
from behavior_detector import BehaviorDetector
from abuseipdb_client import AbuseIPDBClient

# Try scapy import
try:
    from scapy.all import sniff, conf
    conf.verb = 0  # Quiet mode
except ImportError:
    print("ERROR: scapy not installed. Install with: pip install scapy")
    sys.exit(1)


class SensorClient:
    """Remote sensor client that sends alerts to central SOC"""

    def __init__(self, config_file='config.yaml', server_url=None, sensor_id=None,
                 location=None, batch_interval=30):
        """
        Initialize sensor client

        Args:
            config_file: Path to config file
            server_url: Central SOC server URL (e.g., http://soc.example.com:8080)
            sensor_id: Unique sensor identifier
            location: Sensor location description
            batch_interval: Seconds between alert batch uploads
        """
        self.config = load_config(config_file)
        self.server_url = server_url or os.environ.get('SOC_SERVER_URL')
        self.sensor_id = sensor_id or os.environ.get('SENSOR_ID') or self._generate_sensor_id()
        self.location = location or os.environ.get('SENSOR_LOCATION', 'Unknown')
        self.batch_interval = batch_interval
        self.running = False

        # Statistics
        self.packets_captured = 0
        self.alerts_sent = 0
        self.start_time = time.time()

        # Bandwidth tracking
        self.bytes_received = 0
        self.bytes_sent = 0
        self.bandwidth_window_start = time.time()
        self.bandwidth_window_bytes = 0  # Bytes in current measurement window

        # Alert buffer for batching
        self.alert_buffer = deque(maxlen=10000)  # Max 10k alerts in buffer

        # Setup logging
        self._setup_logging()
        self.logger = logging.getLogger('NetMonitor.Sensor')

        # Validate configuration
        if not self.server_url:
            self.logger.error("SOC_SERVER_URL not configured!")
            print("ERROR: Set SOC_SERVER_URL environment variable or pass --server-url")
            sys.exit(1)

        self.logger.info(f"Sensor ID: {self.sensor_id}")
        self.logger.info(f"Location: {self.location}")
        self.logger.info(f"SOC Server: {self.server_url}")

        # Initialize components
        self._init_components()

        # Register with server
        self._register_sensor()

    def _generate_sensor_id(self):
        """Generate unique sensor ID from hostname and MAC address"""
        hostname = socket.gethostname()
        # Try to get MAC address of first non-loopback interface
        try:
            import uuid
            mac = ':'.join(['{:02x}'.format((uuid.getnode() >> elements) & 0xff)
                           for elements in range(0, 2*6, 2)][::-1])
            return f"{hostname}-{mac[:8]}"
        except:
            return f"{hostname}-{int(time.time())}"

    def _setup_logging(self):
        """Setup logging with fallback to console-only if file logging fails"""
        handlers = []

        # Try to setup file logging
        log_dir = '/var/log/netmonitor'
        log_file = os.path.join(log_dir, 'sensor.log')

        try:
            # Create log directory if it doesn't exist
            os.makedirs(log_dir, exist_ok=True)
            # Add file handler
            handlers.append(logging.FileHandler(log_file))
        except (OSError, PermissionError) as e:
            # If we can't create log directory or file, just use console
            print(f"Warning: Cannot create log file {log_file}: {e}")
            print("Logging to console only")

        # Always add console handler
        handlers.append(logging.StreamHandler())

        # Configure logging
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=handlers
        )

    def _init_components(self):
        """Initialize threat detection components"""
        self.logger.info("Initializing threat detection components...")

        # Initialize threat feeds
        if self.config.get('threat_feeds', {}).get('enabled', False):
            try:
                cache_dir = self.config.get('threat_feeds', {}).get('cache_dir', '/var/cache/netmonitor/feeds')
                self.threat_feeds = ThreatFeedManager(cache_dir=cache_dir)
                self.logger.info("Threat Feed Manager enabled")
            except Exception as e:
                self.logger.error(f"Failed to initialize threat feeds: {e}")
                self.threat_feeds = None
        else:
            self.threat_feeds = None

        # Initialize behavior detector
        self.behavior_detector = BehaviorDetector(self.config)
        self.logger.info("Behavior Detector enabled")

        # Initialize AbuseIPDB client
        if self.config.get('abuseipdb', {}).get('enabled', False):
            api_key = self.config.get('abuseipdb', {}).get('api_key', '')
            if api_key:
                try:
                    rate_limit = self.config.get('abuseipdb', {}).get('rate_limit', 1000)
                    self.abuseipdb = AbuseIPDBClient(api_key, rate_limit=rate_limit)
                    self.logger.info("AbuseIPDB client enabled")
                except Exception as e:
                    self.logger.error(f"Failed to initialize AbuseIPDB: {e}")
                    self.abuseipdb = None
            else:
                self.abuseipdb = None
        else:
            self.abuseipdb = None

        # Initialize threat detector
        self.detector = ThreatDetector(
            config=self.config,
            threat_feed_manager=self.threat_feeds,
            behavior_detector=self.behavior_detector,
            abuseipdb_client=self.abuseipdb
        )
        self.logger.info("Threat Detector initialized")

        # Fetch and cache server whitelist
        self._update_whitelist()

    def _update_whitelist(self):
        """Fetch whitelist from SOC server and merge with local config"""
        try:
            response = requests.get(
                f"{self.server_url}/api/whitelist",
                params={'sensor_id': self.sensor_id},
                timeout=10
            )

            if response.status_code == 200:
                result = response.json()
                if result.get('success'):
                    entries = result.get('entries', [])

                    # Extract IP CIDRs from whitelist entries
                    server_whitelist = [entry['ip_cidr'] for entry in entries]

                    # Merge with config whitelist
                    config_whitelist = self.config.get('whitelist', [])
                    combined_whitelist = list(set(config_whitelist + server_whitelist))

                    # Update detector's whitelist
                    self.detector.config['whitelist'] = combined_whitelist
                    self.detector.config_whitelist = self.detector._parse_ip_list(combined_whitelist)

                    self.logger.info(f"✓ Whitelist updated: {len(config_whitelist)} config + {len(server_whitelist)} server = {len(combined_whitelist)} total")
                else:
                    self.logger.warning(f"Failed to fetch whitelist: {result.get('error')}")
            else:
                self.logger.warning(f"Whitelist fetch returned status {response.status_code}")

        except Exception as e:
            self.logger.warning(f"Failed to update whitelist from server: {e}")
            self.logger.info("Continuing with config-only whitelist...")

    def _register_sensor(self):
        """Register sensor with central SOC server"""
        self.logger.info("Registering sensor with SOC server...")

        try:
            # Get sensor information
            hostname = socket.gethostname()
            try:
                ip_address = socket.gethostbyname(hostname)
            except:
                ip_address = None

            # Get version
            version = "1.0.0"  # TODO: Get from package

            response = requests.post(
                f"{self.server_url}/api/sensors/register",
                json={
                    'sensor_id': self.sensor_id,
                    'hostname': hostname,
                    'location': self.location,
                    'ip_address': ip_address,
                    'version': version,
                    'config': {
                        'interface': self.config.get('interface', 'unknown'),
                        'batch_interval': self.batch_interval
                    }
                },
                timeout=10
            )

            if response.status_code == 200:
                self.logger.info("✓ Sensor registered successfully")
            else:
                self.logger.warning(f"Registration failed: {response.text}")

        except Exception as e:
            self.logger.error(f"Failed to register sensor: {e}")
            self.logger.warning("Continuing without registration...")

    def _send_heartbeat(self):
        """Send heartbeat to server"""
        try:
            response = requests.post(
                f"{self.server_url}/api/sensors/{self.sensor_id}/heartbeat",
                timeout=5
            )
            return response.status_code == 200
        except:
            return False

    def _poll_commands(self):
        """Poll server for pending commands"""
        try:
            response = requests.get(
                f"{self.server_url}/api/sensors/{self.sensor_id}/commands",
                timeout=10
            )

            if response.status_code == 200:
                result = response.json()
                if result.get('success') and result.get('commands'):
                    return result['commands']
            return []

        except Exception as e:
            self.logger.error(f"Error polling commands: {e}")
            return []

    def _execute_command(self, command):
        """Execute a sensor command"""
        command_id = command['id']
        command_type = command['command_type']
        parameters = command.get('parameters', {})

        self.logger.info(f"Executing command: {command_type} (ID: {command_id})")

        try:
            # Update status to executing
            requests.put(
                f"{self.server_url}/api/sensors/{self.sensor_id}/commands/{command_id}",
                json={'status': 'executing'},
                timeout=10
            )

            result = {'success': False, 'message': 'Unknown command'}

            # Execute based on command type
            if command_type == 'restart':
                result = {
                    'success': True,
                    'message': 'Sensor will restart in 5 seconds'
                }
                self.logger.warning("RESTART command received - sensor will restart")
                # Update status before restarting
                requests.put(
                    f"{self.server_url}/api/sensors/{self.sensor_id}/commands/{command_id}",
                    json={'status': 'completed', 'result': result},
                    timeout=10
                )
                # Schedule restart
                import subprocess
                subprocess.Popen(['sleep', '5', '&&', 'systemctl', 'restart', 'netmonitor-sensor'])
                return

            elif command_type == 'change_interval':
                new_interval = parameters.get('interval', self.batch_interval)
                old_interval = self.batch_interval
                self.batch_interval = int(new_interval)
                result = {
                    'success': True,
                    'message': f'Batch interval changed from {old_interval}s to {self.batch_interval}s'
                }
                self.logger.info(f"Batch interval changed to {self.batch_interval}s")

            elif command_type == 'get_status':
                uptime = int(time.time() - self.start_time)
                result = {
                    'success': True,
                    'data': {
                        'uptime_seconds': uptime,
                        'packets_captured': self.packets_captured,
                        'alerts_sent': self.alerts_sent,
                        'buffer_size': len(self.alert_buffer),
                        'batch_interval': self.batch_interval
                    }
                }

            elif command_type == 'flush_buffer':
                buffer_size = len(self.alert_buffer)
                self._upload_alerts()
                result = {
                    'success': True,
                    'message': f'Flushed {buffer_size} alerts from buffer'
                }
                self.logger.info(f"Manual buffer flush: {buffer_size} alerts")

            elif command_type == 'update_config':
                # Could reload config file in the future
                result = {
                    'success': False,
                    'message': 'Config update not yet implemented'
                }

            elif command_type == 'update_whitelist':
                # Force whitelist update from server
                old_count = len(self.detector.config.get('whitelist', []))
                self._update_whitelist()
                new_count = len(self.detector.config.get('whitelist', []))
                result = {
                    'success': True,
                    'message': f'Whitelist updated: {old_count} → {new_count} entries'
                }
                self.logger.info(f"Whitelist manually updated via command")

            # Report result
            requests.put(
                f"{self.server_url}/api/sensors/{self.sensor_id}/commands/{command_id}",
                json={'status': 'completed', 'result': result},
                timeout=10
            )

            self.logger.info(f"Command {command_type} completed: {result.get('message', 'OK')}")

        except Exception as e:
            self.logger.error(f"Error executing command {command_type}: {e}")
            # Report failure
            try:
                requests.put(
                    f"{self.server_url}/api/sensors/{self.sensor_id}/commands/{command_id}",
                    json={'status': 'failed', 'result': {'error': str(e)}},
                    timeout=10
                )
            except:
                pass

    def _send_metrics(self):
        """Send performance metrics to server"""
        try:
            # Get system metrics
            cpu_percent = psutil.cpu_percent(interval=1)
            memory = psutil.virtual_memory()
            disk = psutil.disk_usage('/')
            uptime = int(time.time() - self.start_time)

            # Calculate bandwidth (Mbps) over measurement window
            now = time.time()
            window_duration = now - self.bandwidth_window_start

            if window_duration > 0:
                # Convert bytes to Mbps: (bytes * 8) / (duration * 1000000)
                mbps = (self.bandwidth_window_bytes * 8) / (window_duration * 1_000_000)

                # Debug logging for bandwidth calculation
                mb_captured = self.bandwidth_window_bytes / (1024 * 1024)  # Convert to MB
                self.logger.info(f"Bandwidth: {mb_captured:.2f} MB captured in {window_duration:.1f}s = {mbps:.2f} Mbps")
            else:
                mbps = 0.0

            # Reset bandwidth window
            self.bandwidth_window_start = now
            self.bandwidth_window_bytes = 0

            response = requests.post(
                f"{self.server_url}/api/sensors/{self.sensor_id}/metrics",
                json={
                    'cpu_percent': cpu_percent,
                    'memory_percent': memory.percent,
                    'disk_percent': disk.percent,
                    'uptime_seconds': uptime,
                    'packets_captured': self.packets_captured,
                    'alerts_sent': self.alerts_sent,
                    'network_interface': self.config.get('interface', 'unknown'),
                    'bandwidth_mbps': round(mbps, 2)  # Add bandwidth in Mbps
                },
                timeout=10
            )

            if response.status_code == 200:
                self.logger.debug("Metrics sent")
            else:
                self.logger.warning(f"Failed to send metrics: {response.text}")

        except Exception as e:
            self.logger.error(f"Error sending metrics: {e}")

    def _upload_alert_immediate(self, alert):
        """Upload a single high-priority alert immediately"""
        try:
            response = requests.post(
                f"{self.server_url}/api/sensors/{self.sensor_id}/alerts",
                json={'alerts': [alert]},
                timeout=10
            )

            if response.status_code == 200:
                result = response.json()
                self.alerts_sent += result.get('inserted', 0)
                self.logger.info(f"⚡ Immediate upload: [{alert['severity']}] {alert['threat_type']}")
                return True
            else:
                self.logger.warning(f"Failed to upload immediate alert: {response.text}")
                return False

        except Exception as e:
            self.logger.error(f"Error uploading immediate alert: {e}")
            return False

    def _upload_alerts(self):
        """Upload buffered alerts to server in batch"""
        if not self.alert_buffer:
            return

        # Get all alerts from buffer
        alerts = []
        while self.alert_buffer and len(alerts) < 1000:  # Max 1000 per batch
            alerts.append(self.alert_buffer.popleft())

        if not alerts:
            return

        try:
            response = requests.post(
                f"{self.server_url}/api/sensors/{self.sensor_id}/alerts",
                json={'alerts': alerts},
                timeout=30
            )

            if response.status_code == 200:
                result = response.json()
                self.alerts_sent += result.get('inserted', 0)
                self.logger.info(f"✓ Uploaded {result.get('inserted', 0)} alerts (buffer: {len(self.alert_buffer)})")
            else:
                self.logger.warning(f"Failed to upload alerts: {response.text}")
                # Put alerts back in buffer
                for alert in reversed(alerts):
                    self.alert_buffer.appendleft(alert)

        except Exception as e:
            self.logger.error(f"Error uploading alerts: {e}")
            # Put alerts back in buffer
            for alert in reversed(alerts):
                self.alert_buffer.appendleft(alert)

    def _handle_packet(self, packet):
        """Process captured packet"""
        try:
            self.packets_captured += 1

            # Track bandwidth (packet size in bytes)
            # Note: len(packet) includes all layers starting from where scapy captures
            packet_size = len(packet) if hasattr(packet, '__len__') else 0
            self.bandwidth_window_bytes += packet_size

            # Debug: log high packet rates (every 1000 packets)
            if self.packets_captured % 1000 == 0:
                elapsed = time.time() - self.start_time
                pps = self.packets_captured / elapsed if elapsed > 0 else 0
                self.logger.debug(f"Captured {self.packets_captured} packets, avg {pps:.0f} pps")

            # Detect threats
            threats = self.detector.analyze_packet(packet)

            # Process alerts with priority handling
            for threat in threats:
                alert = {
                    'timestamp': datetime.now().isoformat(),
                    'severity': threat.get('severity', 'INFO'),
                    'threat_type': threat.get('type', 'UNKNOWN'),
                    'source_ip': threat.get('source_ip'),
                    'destination_ip': threat.get('destination_ip'),
                    'description': threat.get('description', ''),
                    'metadata': threat.get('metadata', {})
                }

                # Priority-based upload strategy
                severity = threat.get('severity')
                if severity in ['CRITICAL', 'HIGH']:
                    # Upload immediately for high-priority alerts
                    self.logger.warning(f"⚠️  [{severity}] {threat.get('type')}: {threat.get('description')}")
                    success = self._upload_alert_immediate(alert)

                    # If immediate upload fails, add to buffer as fallback
                    if not success:
                        self.alert_buffer.append(alert)
                else:
                    # Batch upload for lower priority alerts
                    self.alert_buffer.append(alert)

        except Exception as e:
            self.logger.error(f"Error processing packet: {e}")

    def start(self):
        """Start sensor client"""
        self.running = True
        self.logger.info("=" * 60)
        self.logger.info("Remote Sensor Client Starting")
        self.logger.info("=" * 60)

        interface = self.config.get('interface', 'eth0')
        self.logger.info(f"Monitoring interface: {interface}")
        self.logger.info(f"Batch upload interval: {self.batch_interval}s")

        # Start upload thread
        import threading

        def upload_loop():
            """Background thread for uploading alerts, metrics, and polling commands"""
            last_upload = time.time()
            last_metrics = time.time()
            last_command_poll = time.time()
            last_whitelist_update = time.time()

            while self.running:
                now = time.time()

                # Upload alerts every batch_interval
                if now - last_upload >= self.batch_interval:
                    self._upload_alerts()
                    last_upload = now

                # Send metrics every 60 seconds
                if now - last_metrics >= 60:
                    self._send_metrics()
                    last_metrics = now
                # Send heartbeat every 30 seconds
                elif now - last_metrics >= 30:
                    self._send_heartbeat()

                # Poll for commands every 30 seconds
                if now - last_command_poll >= 30:
                    commands = self._poll_commands()
                    for command in commands:
                        self._execute_command(command)
                    last_command_poll = now

                # Update whitelist every 5 minutes
                if now - last_whitelist_update >= 300:
                    self._update_whitelist()
                    last_whitelist_update = now

                time.sleep(1)

        upload_thread = threading.Thread(target=upload_loop, daemon=True)
        upload_thread.start()

        # Start packet capture
        self.logger.info("Starting packet capture...")
        try:
            sniff(
                iface=interface,
                prn=self._handle_packet,
                store=0,  # Don't store packets in memory
                stop_filter=lambda _: not self.running
            )
        except KeyboardInterrupt:
            self.logger.info("Received interrupt signal")
        except Exception as e:
            self.logger.error(f"Packet capture error: {e}")
        finally:
            self.stop()

    def stop(self):
        """Stop sensor client"""
        if not self.running:
            return

        self.logger.info("Stopping sensor client...")
        self.running = False

        # Upload remaining alerts
        if self.alert_buffer:
            self.logger.info(f"Uploading {len(self.alert_buffer)} remaining alerts...")
            self._upload_alerts()

        # Send final metrics
        self._send_metrics()

        self.logger.info("Sensor client stopped")
        self.logger.info(f"Total packets captured: {self.packets_captured}")
        self.logger.info(f"Total alerts sent: {self.alerts_sent}")


def main():
    """Main entry point"""
    parser = argparse.ArgumentParser(description='Remote Sensor Client for Network Monitor SOC')
    parser.add_argument('-c', '--config', default='config.yaml', help='Config file path')
    parser.add_argument('-s', '--server-url', help='SOC server URL (e.g., http://soc.example.com:8080)')
    parser.add_argument('--sensor-id', help='Unique sensor ID (auto-generated if not provided)')
    parser.add_argument('-l', '--location', help='Sensor location (e.g., "Building A - VLAN 10")')
    parser.add_argument('-i', '--interval', type=int, default=30, help='Batch upload interval in seconds')
    parser.add_argument('-v', '--verbose', action='store_true', help='Verbose logging')

    args = parser.parse_args()

    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)

    # Create sensor client
    sensor = SensorClient(
        config_file=args.config,
        server_url=args.server_url,
        sensor_id=args.sensor_id,
        location=args.location,
        batch_interval=args.interval
    )

    # Handle signals
    def signal_handler(sig, frame):
        sensor.stop()
        sys.exit(0)

    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)

    # Start sensor
    sensor.start()


if __name__ == '__main__':
    main()
